---
title: "COVID-19 Data ETL"
author: "Rohit Kumar"
date: "2025-02-08"
output: pdf_document
---


```{r setup, warning = FALSE, message = FALSE, include = FALSE}

knitr::opts_chunk$set(echo = TRUE)
require("knitr")

opts_knit$set(root.dir = "C:/Users/William Roche/Downloads/School/Portfolio/Covid Project")

# Setting working directory for the project

library(tidyverse)  # Includes dplyr, ggplot2, tidyr, readr, etc.
library(lubridate)  # For handling date conversions
library(broom)      # For tidying model outputs
library(olsrr)      # For regression diagnostics
library(car)        # Regression diagnostics
library(mctest)     # Multicollinearity test
library(MPV)        # Regression modeling
library(cvTools)    # Cross-validation


# Loading all necessary libraries

#install.packages("gh")
library(gh)  #using Github API to access datasets rather than storing them on local machine




```




# Data Import


## Setting up GitHub Authentication


```{r, warning = FALSE, message = FALSE}

#install.packages("httr")
#install.packages("gitcreds")  # For managing GitHub credentials
#install.packages("usethis")   # For GitHub authentication setup
library(httr)
library(gitcreds)
library(usethis)

```



```{r, warning = FALSE, message = FALSE}
gitcreds_set()

```


```{r, warning = FALSE, message = FALSE}
gitcreds_get()

```

```{r, warning = FALSE, message = FALSE}
#Adding Token
#usethis::edit_r_environ()  # Adding token manually to .Renviron
#readRenviron("~/.Renviron") # Reloading the environment
#Sys.getenv("GITHUB_PAT") # Making sure it is set


#Testing Connection
#usethis::gh_token_help()
#response <- GET("https://api.github.com/user", authenticate("RawHeatEcon", Sys.getenv("GITHUB_PAT")))
#content(response)

```


```{r, warning = FALSE, message = FALSE}

Sys.setenv(GITHUB_PAT = gitcreds_get()$password)
```





## Initial Data Import

```{r, warning = FALSE, message = FALSE}
#install.packages("httr2",type="binary")
library(httr2)
# GitHub repository details
repo <- "CSSEGISandData/COVID-19"
path <- "csse_covid_19_data/csse_covid_19_daily_reports_us"

# Fetching all files in the directory using GitHub API
file_list <- gh("GET /repos/{owner}/{repo}/contents/{path}", 
                owner = "CSSEGISandData", repo = "COVID-19", path = path)

# Extracting the file names and filtering for CSV files
csv_files <- sapply(file_list, function(x) x$name)
csv_files <- csv_files[grepl("\\.csv$", csv_files)]

# List the CSV files
head(csv_files)

```






```{r, warning = FALSE, message = FALSE}
# Base URL for files
base_url <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports_us/"

# Initializing an empty list to store the data
covid_data_list <- list()

# Looping through the files and reading them in batches
for (file in csv_files) {
  # Constructing the raw file URL
  file_url <- paste0(base_url, file)
  
  # Downloading the file and reading it into R
  response <- httr::GET(file_url)
  
  if (httr::status_code(response) == 200) {
    # Reading CSV content into R
    covid_data <- read_csv(httr::content(response, "text"))
    
    # Storing the data (will transform it if needed here)
    covid_data_list[[file]] <- covid_data
  } else {
    cat("Skipping missing file:", file, "\n")
  }
}
#Problem here since, the original GitHub repository directory has been truncated to 1,000 files, ommitting 63 files

# Combine the data if needed (e.g., bind them into one large data frame)
#combined_data <- do.call(rbind, covid_data_list)

# Check the combined data
#head(combined_data)

```

### Confirming Data Import 

```{r, warning = FALSE, message = FALSE}
length(covid_data_list)

```

# Standardizing Data and Combining All Datasets

```{r, warning = FALSE, message = FALSE}

#covid_data_list

```



```{r, warning = FALSE, message = FALSE}


```



```{r, warning = FALSE, message = FALSE}


```

























